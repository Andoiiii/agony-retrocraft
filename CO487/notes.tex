\documentclass[class=co487,tikz,notes]{agony}
\declaretheorem[name=Cryptoscheme,refname={scheme,schemes},style=thmroundpink,sibling=theorem]{scheme}
\declaretheorem[name=Attack,refname={attack,attacks},style=thmroundpink,sibling=theorem]{attack}

\title{CO 487 Winter 2024: Lecture Notes}
\begin{document}
\renewcommand{\contentsname}{CO 487 Winter 2024:\\{\huge Lecture Notes}}
\thispagestyle{firstpage}
\tableofcontents

Lecture notes taken, unless otherwise specified,
by myself during the Winter 2024 offering of CO 487,
taught by Alfred Menezes.

\begin{multicols}{2}
  \listoflecture
\end{multicols}

\chapter{Introduction}
\lecture{Jan 8}

Cryptography is securing communications in the presence of malicious adversaries.
To simplify, consider Alice and Bob communicating with the eavesdropper Eve.
Communications should be:
\begin{itemize}
  \item Confidential: Only authorized people can read it
  \item Integral: Ensured that it is unmodified
  \item Origin authenticated: Ensured that the source is in fact Alice
  \item Non-repudiated: Unable to gaslight the message existing
\end{itemize}
Examples: TLS for intenet browsing, GSM for cell phone communications,
Bluetooth for other wireless devices.

\paragraph{Overview: Transport Layer Security} The protocol used by browsers
to visit websites.
TLS assures an individual user (a \term{client})
of the authenticity of the website (a \term{server})
and to establish a secure communications \term{session}.

TLS uses \term{symmetric-key cryptography}.
Both the client and server have a shared secret $k$ called a \term{key}.
They can then use AES for encryption and HMAC for authentication.

To establish the shared secret, use \term{public-key cryptography}.
Alice can encrypt the session key $k$ can be encrypted with Bob's RSA public key.
Then, Bob can decrypt it with his private key.

To ensure Alice is getting an authentic copy of Bob's public key,
a \term{certification authority} (CA) signs it using the CA's private key.
The CA public key comes with Alice's device preinstalled.

Potential vulnerabilities when using TLS:
\begin{itemize}
  \item Weak cryptography scheme or vulnerable to quantum computing
  \item Weak random number generation for the session key
  \item Fraudulent certificates
  \item Implementation bugs
  \item Phishing attacks
  \item Transmission is secured, but the endpoints are not
\end{itemize}
These are mostly the purview of cybersecurity,
of which cryptography is a part.
Cryptography is not typically the weakest link in the cybersecurity chain.

\chapter{Symmetric Key Encryption}
\lecture{Jan 10}

\section{Basic concepts}

\begin{defn}[symmetric-key encryption scheme]
  A \term*{symmetric-key encryption scheme} (SKES) consists of:
  \begin{itemize}[nosep]
    \item plaintext space $M$,
    \item ciphertext space $C$,
    \item key space $K$,
    \item family of encryption functions $E_k : M \to C$ for all keys $k \in K$, and
    \item family of decryption functions $D_k : C \to M$ for all keys $k \in K$
  \end{itemize}
  such that $D_k(E_k(m)) = m$ for all $m$ and $k$.
\end{defn}

For Alice to send a message to Bob:
\begin{enumerate}[1.,nosep]
  \item Alice and Bob agree on a secret key $k$ \emph{somehow} (assume a secured channel)
  \item Alice computes $c = E_k(m)$ and sends $c$ to Bob
  \item Bob recovers the plaintext by computing $m = D_k(c)$
\end{enumerate}

Examples include the Enigma and Lorenz machines.

\begin{scheme}[simple substitution cipher]
  Let:
  \begin{itemize}[nosep]
    \item $M$ be English messages
    \item $C$ be encrypted messages
    \item $K$ be permutations of the English alphabet
    \item $E_k(m)$ apply the permutation $k$ to $m$, one letter at a time
    \item $D_k(c)$ apply the inverse permutation $k^{-1}$ to $c$, one letter at a time
  \end{itemize}
\end{scheme}

We want a system to have:
\begin{enumerate}[nosep]
  \item Efficient algorithms should be known for computing (encryption and decryption)
  \item Small keys but large enough to render exhaustive key search infeasible
  \item Security
  \item Security against its designer
\end{enumerate}

To determine how secure the protocol is, we have to define security.

\begin{defn}[security model]
  Some parameters which define the strength of the adversary,
  specific interaction with the ``secure'' channel,
  and the goal of the adversary.
\end{defn}

Some options for strength:
\begin{itemize}[nosep]
  \item \term[security!information-theoretic]{Information-theoretic security}: Eve has infinite resources.
  \item \term[security!complexity-theoretic]{Complexity-theoretic security}: Eve is a polynomimal-time Turing machine.
  \item \term[security!computational-theoretic]{Computational-theoretic security}: Eve has a specific amount of computing power.
        In this course, Eve is \term{computationally bounded} by
        6,768 Intel E5-2683 V4 cores running at 2.1 GHz at her disposal.
\end{itemize}
For the interaction:
\begin{itemize}[nosep]
  \item \term[attack!ciphertext-only]{Ciphertext-only attack}: Eve only knows the ciphertext.
  \item \term[attack!known-plaintext]{Known-plaintext attack}: Eve knows some plaintext and the corresponding ciphertext.
  \item \term[attack!chosen-plaintext]{Chosen-plaintext attack}: Eve picks some plaintext and knows the corresponding ciphertext.
  \item \term[attack!clandestine]{Clanedestine attack}: Eve resorts to bribery, blackmail, etc.
  \item \term[attack!side-channel]{Side-channel attack}: Eve has physical access to hardware and has some monitoring data.
\end{itemize}
And for the goal:
\begin{itemize}[nosep]
  \item Recovering the secret key $k$
  \item Systematically decrypt arbitrary ciphertexts without knowing $k$ (\term{total security})
  \item Learn partial information about the plaintext (other than the length) (\term{semantic security})
\end{itemize}

\begin{defn}[security]
  An SKES is \term{secure} if it is semantically secure against a chosen-plaintext attack
  by a computationally bounded adversary.
\end{defn}

Equivalently, an SKES is \term{broken} if:
\begin{enumerate}[nosep]
  \item Given a challenge ciphertext $c$ for $m$ generated by Alice,
  \item \dots and access to an encryption oracle for Alice,
  \item \dots Eve can obtain some information about $m$ other than its length,
  \item \dots using only a feasible amount of computation.
\end{enumerate}
Note: this is IND--CPA from CO 485.

\begin{example}
  Is the simple substitution cipher secure?
  What about under a ciphertext-only attack?
\end{example}
\begin{sol}
  Under CPA, encrypt the entire alphabet.
  Then, the entire key $k$ is recovered.

  With a ciphertext-only attack, an exhaustive key search would take
  $26! \approx 2^{88}$ attempts.
  This would take over 1,000 years, which is pretty infeasible,
  so it is secure.
\end{sol}

Can we quantify how feasible something is?

\begin{defn}[security level]
  A scheme has a \term{security level} of $\ell$ bits if
  the fastest known attack on the scheme takes approximately $2^\ell$ operations.
\end{defn}

\begin{convention}
  In this course:
  \begin{itemize}[nosep]
    \item 40 bits is very easy to break
    \item 56 bits is easy to break
    \item 64 bits is feasible to break
    \item 80 bits is barely feasible to break
    \item 128 bits is infeasible to break
  \end{itemize}
\end{convention}

\lecture{Jan 12}
The simple substitution cipher can be attacked by frequency analysis,
since, for example, if ``e'' is the most common English letter,
we check the ciphertext for the most common letter and identify it with ``e''.

\begin{scheme}[Vigen√®re cipher]
  Let the key $K$ be an English word with no repeated letters, e.g., $K = \symrm{CRYPTO}$.

  To encrypt, add letter-wise the key modulo 26, where $k$ is $K$ repeated until
  it matches the length of the message:
  \begin{center}
    \begin{tabular}{rcccccccccccccc}
      $m =$        & t & h & i & s & i & s & a & m & e & s & s & a & g & e \\
      $+\quad k =$ & C & R & Y & P & T & O & C & R & Y & P & T & O & C & R \\ \hline
      $c =$        & V & Y & G & H & B & G & C & D & C & H & L & O & I & V
    \end{tabular}
  \end{center}
  To decrypt, just take $c - k$.
\end{scheme}

This solves our frequency analysis problem.
However, the Vigenere cipher is still totally insecure.

\begin{xca}
  Show that the Vigenere cipher is totally insecure under a chosen-plaintext attack
  and a ciphertext-only attack.
\end{xca}

\begin{scheme}[one-time pad]
  The key is a random string of letters with the same length as the message.

  Repeat the process for Vigenere.
  To encode, add each letter.
  To decode, subtract each letter.
\end{scheme}

\begin{example}
  We can encrypt as follows:
  \begin{center}
    \begin{tabular}{rcccccccccccccc}
      $m =$        & t & h & i & s & i & s & a & m & e & s & s & a & g & e \\
      $+\quad k =$ & Z & F & K & W & O & G & P & S & M & F & J & D & L & G \\ \hline
      $c =$        & S & M & S & P & W & Y & P & F & Q & X & C & D & R & K \\
    \end{tabular}
  \end{center}
\end{example}

This is semantically secure as long as the key is never reused.
Formally, there exist keys that can decrypt the ciphertext into \emph{anything},
so there is no way for an attacker to know the plaintext.
If it is reused, i.e., if $c_1 = m_1 + k$ and $c_2 = m_2 + k$,
then $c_1 - c_2 = (m_1 + k) - (m_2 + k) = m_1 - m_2$.
Since this is a function only of messages, it can leak frequency information etc.

Also, since the key is never reused, this is secure against a chosen plaintext attack,
since one would only recover the already used key.

\begin{convention}
  From now on, messages and keys are assumed to be binary strings.
\end{convention}

\begin{defn}[bitwise exclusive or]
  For two bitstrings $x,y \in \{0,1\}^n \cong \Z/2\Z^n$,
  the bitwise XOR $x \xor y$ is just addition mod 2.
\end{defn}

Unfortunately, due to Shannon, we have this theorem:

\begin{theorem}
  A perfectly secure symmetric-key scheme must have
  at least as many keys as there are messages.
\end{theorem}

\section{Stream ciphers}

Instead of using a random key in the OTP, use a pseudorandom key.

\begin{defn}[pseudorandomness]
  A \term*{pseudorandom bit generator} (PBRG) is a deterministic algorithm
  that takes as input a \term{seed} and outputs a \term*{pseudorandom} sequence called
  the \term{keystream}.
\end{defn}

Then, we can construct a stream cipher by defining the key as the seed
and the ciphertext as the keystream XOR'd with the plaintext.
To decrypt, use the seed to generate the same keystream and XOR with the ciphertext.

For a stream cipher to be secure, we need:
\begin{itemize}
  \item Indistinguishability: the keystream is indistinguishable from a
        truly random sequence; and
  \item Unpredictability: given a partial keystream, it is infeasible to learn
        any information from the remainder of the keystream.
\end{itemize}

\begin{remark}
  Do not use built-in UNIX \texttt{rand} or \texttt{srand} for cryptography!
\end{remark}

Now, we introduce ChaCha20, a stream cipher actually uesd in the real world.
The algorithm works entirely on words (32-bit numbers).
It has no known flaws (other than people bungling the implementation).

\begin{scheme}[ChaCha20]
  First, define a helper function $QR(a,b,c,d)$ on 32-bit words:
  \begin{enumerate}[nosep]
    \item $a \gets a \modplus b$, $d \gets d \xor a$, $d \gets d \lll 16$
    \item $c \gets c \modplus d$, $b \gets b \xor c$, $b \gets b \lll 12$
    \item $a \gets a \modplus b$, $d \gets d \xor a$, $d \gets d \lll 8$
    \item $c \gets c \modplus d$, $b \gets b \xor c$, $b \gets b \lll 7$
  \end{enumerate}
  where $\xor$ is bitwise XOR, $\modplus$ is addition mod $2^{32}$, and $\lll$ is left bit-rotation.

  Given a 256-bit key $k = (k_1,\dotsc,k_8)$,
  a selected 96-bit nonce $n = (n_1,n_2,n_3)$,
  a 128-bit given constant $f = (f_1,\dotsc,f_4)$,
  and 32-bit counter $c \gets 0$, construct an initial state:
  \[
    S := \begin{bmatrix}
      f_1 & f_2 & f_3 & f_4 \\
      k_1 & k_2 & k_3 & k_4 \\
      k_5 & k_6 & k_7 & k_8 \\
      c   & n_1 & n_2 & n_3
    \end{bmatrix} = \begin{bmatrix}
      S_1    & S_2    & S_3    & S_4    \\
      S_5    & S_6    & S_7    & S_8    \\
      S_9    & S_{10} & S_{11} & S_{12} \\
      S_{13} & S_{14} & S_{15} & S_{16}
    \end{bmatrix}
  \]
  Keep a copy $S' \gets S$, then apply:
  \begin{gather*}
    QR(S_{1}, S_{5}, S_{9}, S_{13}),\quad QR(S_{2}, S_{6}, S_{10}, S_{14}),\quad QR(S_{3}, S_{7}, S_{11}, S_{15}),\quad QR(S_{4}, S_{8}, S_{12}, S_{16}) \\
    QR(S_{1}, S_{6}, S_{11}, S_{16}),\quad QR(S_{2}, S_{7}, S_{12}, S_{13}),\quad QR(S_{3}, S_{8}, S_{9}, S_{14}),\quad QR(S_{4}, S_{5}, S_{10}, S_{15})
  \end{gather*}
  ten times (for 80 total calls to $QR$) and output $S \xor S'$.
  This gives us 64 keystream bytes.

  Increment $c \gets c+1$ and repeat as necessary to generate more keystream bytes.

  To encrypt, XOR the keystream with the plaintext, then append the nonce.

  To decrypt, pop off the nonce, then XOR the keystream with the ciphertext.
\end{scheme}

\lecture{Jan 15}
One must be careful never to reuse nonces, since this results in the same keystream,
leading to recoverable messages.
In practice, this is hard (e.g., two devices with the same key).

Miscellaneous remarks:
\begin{itemize}[nosep]
  \item Why is ChaCha20 so good? The $QR$ function is very fast at the hardware level
        and there is wide adoption/standardization by experts.
  \item Why 10 rounds? If you do 1 or 2 rounds, there is a trivial attack.
        The latest theoretical attacks can attack 7 rounds
        (currently infeasible, but still better than exhaustive key search).
        So 8 rounds is secure and we do 10 to be safe.
  \item Is this secure forever (i.e., can we always just increase rounds)?
        No. Nothing in this course is.
        Someone could find a super crazy PMATH theorem that shows
        predictability of the $QR$ scramble.
\end{itemize}

\section{Block ciphers}

\begin{defn}[block cipher]
  Like a stream cipher, but instead of processing one character at a time,
  we break up the plaintext into \term[block]{blocks} of equal length
  and encrypt block-wise.
\end{defn}

\begin{example}
  The Data Encryption Standard (DES) is a standard
  56-bit key and 64-bit blocks.
\end{example}

\paragraph{Aside: History and the NSA doing ratfuckery}
In 1972, the National Institute of Standards and Technology (NIST)\footnote{of standardized peanut butter fame}
puts out an RfP for encryption algorithms.

IBM developed and proposed 64-bit DES, but then the NSA reduced it in 1975
to 56-bit so they can do some spying.
This made DES feasible to break by nation-states but not smaller organizations.

The National Security Agency (NSA)
is the US' signals intelligence (SIGINT; hacking foreign intelligence)
and information insurance (IA; defending domestic intelligence) agency.
They have a history of regulating how strong cryptoraphic products can be
by banning the export of strong cryptography.

Canada has an NSA equivalent: the Communications Security Establishment (CSE).
Along with the Kiwi CCSA, British GCHQ, and Australian ASD,
these are the Five Eyes who spy on just about everyone.


We only really know stuff about the NSA/Five Eyes due to the Snowden leaks.
For example, the SIGINT Enabling Project attempts to influence/blackmail
companies to weaken their security with backdoors.

Throughout the course, we will use the NSA to mean ``generic nation-state level adversary'',
since if you can defeat the NSA, you can defeat basically anyone.

Anyways, weakened DES was adopted by NIST in 1977 as FIPS 46 in 1977,
then as a banking standard as ANSI X3.92 in 1982 (replaced by Triple-DES in 1988).
From 1997--2001, a new contest developed the Advanced Encryption Standard (AES),
which is the current standard block cipher.

\paragraph{Desired properties of block ciphers} (Shannon, 1949):
\begin{enumerate}[nosep]
  \item Diffusion: Each ciphertext bit should depend on all plaintext bits.
  \item Confusion: The key--ciphertext relationship should be complicated.
  \item Key length: Keys should be small but not too small to be searchable.
  \item Simplicity: Ease of implementation and analysis.
  \item Speed: Runs quickly on all reasonable hardware.
  \item Platform: Can be implemented in hardware and software.
\end{enumerate}

\begin{scheme}[DES]
  The design principles of DES are still classified,
  so we just treat it as a black box for this course.
  We only need to know that there is a 56-bit key and 64-bit blocks.
\end{scheme}

The DES key space is not very big.
Exhaustive search on DES takes $2^{56}$ operations.
In 1997, this took three months.
In 2012, it takes 11.5 hours.

The blocks are also not very large.
By the birthday paradox, there is a collision every $2^{32}$ blocks.
This is an information leak, breaking semantic security.

These are the only (known) weaknesses in DES.

\begin{defn}[multiple encryption]
  Re-encrypt the ciphertext more times with different keys.
\end{defn}

This is not always more secure. For example, in the simple substitution cipher,
permutations can be composed and do not introduce more security.

\begin{scheme}[Double-DES]
  Pick a secret key $k = (k_1,k_2) \randin \{0,1\}^{112}$.

  Then, encrypt $E_{k_2}(E_{k_1}(m))$ where $E$ is DES encryption

  Likewise, decrypt $E^{-1}_{k_2}(E^{-1}_{k_1}(m))$ where $E^{-1}$ is DES decryption.
\end{scheme}

We now have an exhaustive key search of $2^{112}$ operations, which is better.
However, there is an attack which reduces this to breaking DES.

\textrule{$\downarrow$ Lectures 5, 6, and 7 taken directly from slides $\downarrow$}
\lecture{Jan 17}
\lecture{Jan 19}

\chapter{Hash functions}

\section{Definitions}
\lecture{Jan 22}

\begin{defn}[hash function]
  A mapping $H$ such that
  \begin{enumerate}
    \item $H : \{0,1\}^{\leq L} \to \{0,1\}^n$ maps binary messages
          of arbitrary lengths $\leq L$ to outputs of a fixed length $n$.
    \item $H(x)$ can be efficiently computed for all $x \in \{0,1\}^{\leq L}$
  \end{enumerate}
  is an \term*{$n$-bit hash function}.
  We call $H(x)$ the \term{hash} or \term{digest} of $x$.

  We usually suppose that $L$ is large and just write $H : \hash{n}$.
\end{defn}

In a more general context, a hash function is an efficiently computable function.

\begin{example}
  Let $H : \{0,1\}^{\leq4} \to \{0,1\}^2$
  be a hash function mapping a bitstring to its last two digits.
  For example, $H(1101) = 01$.

  We call 1001 a \term{preimage} of 01.

  The pair $(01, 1001)$ is a \term{collision}
  where 01 is a \term{second preimage} of 1001.
\end{example}

Generically, we can create a hash function given a block cipher.

\begin{scheme}[Davies--Meyer hash function]
  Let $E_k$ be an $m$-bit block cipher with $n$-bit key $k$.
  Let $\vv{IV}$ be a fixed $m$-bit initializing value.

  Then, to compute $H(x)$,
  \begin{enumerate}[noitemsep]
    \item Break up $x \| 1$ into $n$-bit blocks $\bar x = x_1,\dotsc,x_t$
          (padding $x_t$ with 0s if necessary)
    \item $H_0 \gets \vv{IV}$
    \item $H_i \gets E_{x_i}(H_{i-1}) \xor H_{i-1}$ for all $i=1,\dotsc,t$
    \item $H(x) \gets H_t$
  \end{enumerate}
\end{scheme}

Hash functions are used basically everywhere in cryptography,
mostly just because they are stupidly fast and introduce ``scrambling'' that,
given a good enough hash function, cannot be reversed.

\begin{defn}[preimage resistance]
  A hash function $H = \hash{n}$ is \term*{preimage resistant} (PR) if,
  given a hash value $y \randin \{0,1\}^n$, it is computationally infeasible
  to find any $x \in \{0,1\}^*$ with $H(x) = y$ with non-negligible success probability.
\end{defn}

Note that we include disclaimers like ``non-negligible success probability''
since otherwise we could just use an attack like ``guess! it might just work!''

This is helpful for implementing passwords.
If we store $(\vv{password}, H(\vv{password}))$ with a PR hash $H$,
then stealing the system password file does not actually reveal the passwords.

\begin{defn}[2\nd preimage resistance]
  A hash function $H = \hash{n}$ is \term*{2\nd preimage resistant} (2PR) if,
  given $x \randin \{0,1\}^*$, it is computationally infeasible to find
  any $x' \in \{0,1\}^*$ with $x' \neq x$ and $H(x') = H(x)$ with non-negligible success probability.
\end{defn}

This is helpful for ensuring that a message is unchanged
(Modification Detection Codes; MDCs).
To ensure a message $m$ is unmodified, publicize $H(m)$.
Then, as long as $H$ is 2PR and we can verify the hash,
we can safely assume $m$ is unmodified.

\begin{defn}[collision resistance]
  A hash function $H = \hash{n}$ is \term*{collision resistant} (CR)
  if it is computationally infeasible to find distinct $x,x' \in \{0,1\}^*$
  where $H(x') = H(x)$.
\end{defn}

This allows us to optimize message signing.
Instead of signing a large file $x$, Alice can sign $H(x)$ instead.
Keeping all the desired properties of a signing scheme
requires PR, 2PR, and CR.

\textrule{$\uparrow$ Lectures 5, 6, and 7 taken directly from slides $\uparrow$}
\lecture{Jan 24}

\begin{prop}
  If $H$ is CR, then $H$ is 2PR.
\end{prop}
\begin{prf}
  Take the contrapositive: $H$ is not 2PR $\implies$ $H$ is not CR.

  Suppose $H$ is not 2PR, i.e., we have an efficient algorithm
  to find a collision $x'$ given $x$.

  Select a random $x$. Get the collision $x'$ from our algorithm.
  Then, we have a collision $(x,x')$ that we found efficiently,
  so $H$ is not CR.
\end{prf}

It will \emph{always} be easier to do the contrapositive in this course,
especially because most definitions use ``it is not possible''.

\begin{prop}
  CR does not guarantee PR.
\end{prop}
\begin{prf}
  We give a counterexample.

  Suppose that $H : \{0,1\}^* \to \{0,1\}^n$ is CR.

  Consider the hash function $\bar H = \{0,1\}^* \to \{0,1\}^{n+1}$ defined by
  \[
    \bar H(x) = \begin{cases}
      0 \| H(x) & x \not\in \{0,1\}^n \\
      1 \| x    & x \in \{0,1\}^n
    \end{cases}
  \]
  where $\|$ denotes the concatenation operation. Then $\bar H$ is CR because $H$ is.

  However, $\bar H$ is not PR for at least half of all $y \in \{0,1\}^{n+1}$
  we can efficiently find the preimage (i.e., for all the hash values beginning with 1,
  we can just lop off the 1 to get the original).
\end{prf}

Note: if we disallow pathological hash functions like this, i.e.,
we have some constraint on uniformity in the size of preimages,
CR does guarantee PR.

\begin{prop}
  Suppose $H$ is \term{somewhat uniform}, i.e., preimages are all around the same size.
  If $H$ is CR, then $H$ is PR.
\end{prop}
\begin{prf}
  Suppose that $H : \{0,1\}^* \to \{0,1\}^n$ is not PR.
  We must show $H$ is not CR.

  Select $x \randin \{0,1\}^*$ and compute $y = H(x)$.
  Since $H$ is not PR, we can efficiently find $x' \in \{0,1\}^*$ with $H(x') = y$.
  Since $H$ is somewhat uniform, we expect that $y$ has many preimages,
  so $x' \neq x$ with very high probability.

  Therefore, $(x,x')$ is a collision and $H$ is not CR.
\end{prf}

\begin{prop}
  PR does not guarantee 2PR.
\end{prop}
\begin{prf}
  Suppose that $H : \{0,1\}^* \to \{0,1\}^n$ is PR.

  Define $\bar H : \{0,1\}^* \to \{0,1\}^n$ by $\bar H(x_1x_2\dots x_t) = H(0x_2\dots x_t)$.

  Then, $\bar H$ is PR but not 2PR.
\end{prf}

\begin{prop}
  Suppose $H$ is somewhat uniform. If $H$ is 2PR, then $H$ is PR.
\end{prop}
\begin{prf}
  Suppose that $H : \{0,1\}^* \to \{0,1\}^n$ is not PR and show it is not 2PR.

  Suppose we are given $x \{0,1\}^*$.
  Compute $y = H(x)$ and then find with our PR-breaking algorithm $x'$ with $H(x') = y$.
  Since $H$ is somewhat uniform, we expect $x \neq x'$.

  Then, we have a collision $x'$ for $x$ and that breaks PR.
\end{prf}

\begin{prop}
  2PR does not guarantee CR.
\end{prop}
\begin{prf}
  Suppose that $H : \{0,1\}^* \to \{0,1\}^n$ is 2PR.

  Consider $\bar H : \{0,1\}^* \to \{0,1\}^n$ defined by $\bar H(x) = H(x)$
  except $\bar H(1) = H(0)$.

  Then, $\bar H$ is not CR because $(0,1)$ is a collision.

  However, we can show $\bar H$ is 2PR. Suppose $\bar H$ is \emph{not} 2PR.
  We show $H$ would also not be 2PR.

  Suppose we are given some $x$.
  Since $\bar H$ is not 2PR, we can find $x' \neq x$ with $\bar H(x') = \bar H(x)$.
  With almost certain probability, we can assume $x \neq 0,1$.
  Then, $\bar H(x) = H(x)$.
  If $x' \neq 1$, we have $\bar H(x') = H(x') = H(x)$.
  Otherwise, $\bar H(x') = \bar H(1) = H(0) = H(x)$
  We found a second preimage $x'$ or 0 for $x$, so $H$ is not 2PR.

  Therefore, by contradiction, $\bar H$ is 2PR.
\end{prf}

\begin{theorem}[relation between PR, 2PR, CR]
  Summarize:
  \begin{center}
    \begin{tabular}{r|ccc}
      If $H$ is $\downarrow$, then it is $\rightarrow$ & PR        & 2PR         & CR          \\ \hline
      PR                                               & --        & $\not\Rarr$ & $\not\Rarr$ \\
      2PR                                              & $\Rarr^*$ & --          & $\not\Rarr$ \\
      CR                                               & $\Rarr$   & $\Rarr^*$   & --
    \end{tabular}
  \end{center}
  where $\Rarr^*$ means ``implies under somewhat uniformity''
\end{theorem}

\section{Attacks}
\lecture{Jan 26}

\begin{defn}[generic attack]
  An attack which does not exploit any specific properties of a hash function.
  That is, it works on any generic hash function $H : \{0,1\}^* \to \{0,1\}^n$.
\end{defn}

To analyze a generic attack, we assume $H$ is a random function
in the sense that $y = H(x)$ can be treated as $y \randin \{0,1\}^n$.

\begin{attack}[generic attack for preimages]
  Given $y \randin\{0,1\}^n$, repeatedly select arbitrary $x$ until $H(x) = y$.
\end{attack}

This will take $2^n$ attempts, so as long as $n \geq 128$ we are safe.

\begin{attack}[generic attack for collisions]
  Select arbitrary $x \in \{0,1\}^*$ and store $(H(x),x)$ in a table
  sorted by the first entry. Repeat until a collision is found.
\end{attack}

By the birthday paradox, the expected number of hash operations is
$\sqrt{\pi 2^n/2} \approx \sqrt{2^n}$.
Therefore, the attack is infeasible for $n \geq 256$.

The space complexity is also $\order{\sqrt{2^n}}$.
This is important since, for example, $n=128$ has a feasible runtime $2^{64}$
but an infeasible space requirement of 500 million TB.

We can prove that this is the optimal generic collision attack, i.e.,
no faster generic attack exists.

However, we can improve the space complexity.

Let $N = 2^n$.
Define a sequence $(x_i)_{i\geq0}$ by $x_0 \randin \{0,1\}^n$
and $x_i = H(x_{i-1})$.

Since $(x_i) \subseteq \{0,1\}^n$, we will eventually get repetitions.
Therefore, $(x_i)$ is eventually periodic, i.e.,
we will eventually get $x_a = x_b$ for $a \neq b$.
Then, we found a collision $(x_{a-1}, x_{b-1})$.

More formally, let $j$ be the smallest index for which $x_j = x_i$
for some $i < j$, which must exist.
Then, $x_{j+\ell} = x_{i+\ell}$ for all $\ell \geq 1$.

By the birthday paradox, $\E[j] \approx \sqrt{\pi N/2} \approx \sqrt{N}$.
In fact, since $i$ is a random element from before $j$,
we can say $\E[i] \approx \frac12\sqrt{N}$ and $\E[j-i] \approx \frac12\sqrt{N}$.

We will store only some \term*{distinguished points},
for example, elements where the top 32 bits are all 0.
Let $\theta$ be the proportion of distinguished points.
Here, $\theta = 2^{-32}$.

We can still tell detect a cycle as long as there is a distinguished point in the cycle.
Once we detect a collision, we work through the sequence near it.

\begin{attack}[van Oorschot--Wiener parallel collision search]
  We write this attack as two stages:
  \begin{algorithmic}[1]
    \State Create a table $T$
    \Procedure{DetectCollision}{$H$}
      \State Select $x_0 \randin \{0,1\}^n$
      \State $T[x_0] \gets (0,-)$ \Comment{store (index, last distinguished point)}
      \State $c \gets 0$ \Comment{last distinguished point}
      \For{$d = 1,2,3\dotsc$}
        \State $x_d \gets H(x_{d-1})$
        \If{$x_d$ is distinguished}
          \If{$T[x_d]$ exists as $(b,x_a)$}
            \State $(a,-) \gets T[x_a]$ \Comment{need the index of $x_a$}
            \State \Return{\Call{FindCollision}{$x_a,x_c,a,b,c,d$}}
          \EndIf
          \State $T[x_d] \gets (d,c)$
          \State $c \gets d$
        \EndIf
      \EndFor
    \EndProcedure
    \Procedure{FindCollision}{$x_a,x_c,a,b,c,d$}
      \State $\ell_1 \gets b-a$, $\ell_2 \gets d-c$
      \State Suppose $\ell_1 \geq \ell_2$ so $k \gets \ell_1 - \ell_2$
      \State Compute $x_{a+1},\dotsc,x_{a+k}$
      \State $m \gets 1$
      \Repeat
        \State Compute $x_{a+k+m}, x_{c+m}$
        \State $m \gets m + 1$
      \Until{$x_{a+k+m} = x_{c+m}$}
      \State \Return{$(x_{a+k+m-1}, x_{c+m-1})$} \Comment{the collision is $H(x_{a+k+m-1}) = H(x_{c+m-1})$}
    \EndProcedure
  \end{algorithmic}
\end{attack}

In stage 1, we will call the hash function
$\sqrt{\pi N/2} + \frac{1}{\theta}$ times.

In stage 2, we perform at most $\frac{3}{\theta}$ hashes.

In total, we expect to take $\sqrt{N}+\frac{4}{\theta}$ time.
But this time we only need $3n\theta\sqrt{N}$ space.

So for our $n=128$ case with $\theta=2^{-32}$,
the expected runtime is $2^{64}$ hashes (feasible)
and the expected storage is 192 GB (negigible).

\pagebreak
\phantomsection\addcontentsline{toc}{chapter}{Back Matter}
\renewcommand{\listtheoremname}{List of Named Results}
\phantomsection\addcontentsline{toc}{section}{\listtheoremname}
\listoftheorems[ignoreall,numwidth=3em,onlynamed={theorem,lemma,corollary,prop}]
\renewcommand{\listtheoremname}{List of Cryptosystems}
\phantomsection\addcontentsline{toc}{section}{\listtheoremname}
\listoftheorems[ignoreall,onlynamed={scheme}]
\printindex


\end{document}
